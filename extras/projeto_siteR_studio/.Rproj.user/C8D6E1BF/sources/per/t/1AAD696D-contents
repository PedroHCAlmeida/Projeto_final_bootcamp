---
title: Previsões
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: false
    css: styles.css
---

# Previsão da necessidade de cuidados intensivos

```{python}
import sys

print(sys.executable)
```

# Resumo

# Contexto do problema

# Escopo

# Importação dos pacotes

```{python}
import pandas as pd
from scipy.stats import normaltest
import matplotlib.pyplot as plt
import seaborn as sns
import time

from sklearn.feature_selection import SelectFromModel
from sklearn.model_selection import RepeatedStratifiedKFold, RandomizedSearchCV
from sklearn.pipeline import Pipeline
from pipelinehelper import PipelineHelper
from sklearn.utils import resample

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier

import warnings
import os
```

```{python}
warnings.filterwarnings('ignore')
SEED = 64541
```

# Importações das funções locais

```{python}
os.chdir("../.../funcoes")
from my_classifier import Classifier
os.chdir("../extras/projeto_siteR_studio")
```

# Leitura dos dados pré-processados

```{python}
df = pd.read_csv('../dados/dados_preprocessados/preprocessados.csv')
```

```{python}
sns.set_style('darkgrid')
```

```{python}
df.head()
```

# Validação Cruzada

A validação cruzada é um método estatístico usado para estimar a habilidade dos modelos de aprendizado de máquina, portanto a fim de tentar resumir a performance de um modelo de Machine Learning e, escolher o melhor modelo para o problema em questão. Essa técnica consiste em realizar divisões dentro do dataset inteiro entre dados de treino e teste de forma const 

![CV](../img/dataml_cross_validation.png)

### RepeatedStratifiedKFold

porém realizando divisões no dataset de forma que as proporções da variável dependente se mantivessem as mais próximas possíveis em toda a divisão, e além disso realizando essa validação cruzada diversas vezes para que, com isso, consiga resumir a performance de um modelo da maneira mais realista possível.

# Métricas

# Primeiros modelos

```{python}
lr = Classifier(LogisticRegression, df, max_iter=1000)
lr.cross_val()
```

```{python}
dt = Classifier(DecisionTreeClassifier, df)
dt.cross_val()
```

```{python}
rf = Classifier(RandomForestClassifier, df)
rf.cross_val()
```

```{python}
et = Classifier(ExtraTreesClassifier, df)
et.cross_val()
```

```{python}
xg = Classifier(XGBClassifier, df, verbosity=0)
xg.cross_val()
```

```{python}
lgbm = Classifier(LGBMClassifier, df, verbosity=-1)
lgbm.cross_val()
```

```{python}
ax = lr.plot_roc_curve()
dt.plot_roc_curve(ax=ax)
rf.plot_roc_curve(ax=ax)
xg.plot_roc_curve(ax=ax, name_estimator='XGBoost()')
lgbm.plot_roc_curve(ax=ax)
et.plot_roc_curve(ax=ax)
plt.show()
```

# Reamostragem

```{python}
df['ICU'].value_counts()
```

```{python}
icu0 = df.query('ICU == 0')
icu1 = df.query('ICU == 1')
```

```{python}
icu1_resample = resample(icu1,
                         n_samples=len(icu0),
                         random_state=SEED)
```

```{python}
df_resample = pd.concat([icu1_resample, icu0], axis=0)
df_resample['ICU'].value_counts()
```

```{python}
lr = Classifier(LogisticRegression, df_resample, max_iter=1000)
lr.cross_val()
```

```{python}
dt = Classifier(DecisionTreeClassifier, df_resample)
dt.cross_val()
```

```{python}
rf = Classifier(RandomForestClassifier, df_resample)
rf.cross_val()
```

```{python}
et = Classifier(ExtraTreesClassifier, df_resample)
et.cross_val()
```

```{python}
xg = Classifier(XGBClassifier, df_resample, verbosity=0)
xg.cross_val()
```

```{python}
lgbm = Classifier(LGBMClassifier, df_resample, verbosity=-1)
lgbm.cross_val()
```

```{python}
ax = lr.plot_roc_curve()
dt.plot_roc_curve(ax=ax)
rf.plot_roc_curve(ax=ax)
xg.plot_roc_curve(ax=ax, name_estimator='XGBoost()')
lgbm.plot_roc_curve(ax=ax)
et.plot_roc_curve(ax=ax)
plt.show()
```

### Otimização dos hiperparâmetros

```{python}
cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=SEED)
X = df_resample.drop('ICU', axis=1)
y = df_resample['ICU']
```



